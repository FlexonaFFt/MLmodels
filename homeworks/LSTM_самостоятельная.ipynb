{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k7gR7nCclRKO",
        "INf_Dpgy79gu"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Выполнение задания по LSTM"
      ],
      "metadata": {
        "id": "21m6FHjqlHPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пробуем создать и обучить модель на базе LSTM"
      ],
      "metadata": {
        "id": "k7gR7nCclRKO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SmWgEzwlEQ5",
        "outputId": "25c58fd3-ae1b-4418-94e4-10ccb8300572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
            "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
            "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
            "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
            "       'Promo2SinceYear', 'PromoInterval'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Импортируем библиотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers # type: ignore (чтобы жёлтым не подчёркивало)\n",
        "\n",
        "# Сразу же подготавливаем наши файлы (store.csv | train.csv)\n",
        "train = pd.read_csv('train.csv', low_memory=False)\n",
        "store = pd.read_csv('store.csv')\n",
        "# Объединяем данные по идентификатору магазина\n",
        "data = pd.merge(train, store, on='Store', how='left')\n",
        "print(data.columns)\n",
        "# data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготавливаем признаки (извлекаем год, месяц, день | удаляем дату)\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "data = data.drop(columns=['Date'])\n",
        "\n",
        "# Удаляем ненужные строки и столбцы\n",
        "data = data[data['Open'] == 1]\n",
        "data = data.drop(columns=['Open', 'Customers'])\n",
        "\n",
        "# Заполняем пропуски значениями для корректного обучения\n",
        "data['CompetitionDistance'] = data['CompetitionDistance'].fillna(data['CompetitionDistance'].median())\n",
        "data['PromoInterval'], _ = pd.factorize(data['PromoInterval'])\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Преобразуем категориальные переменные в числовые\n",
        "data = pd.get_dummies(data, columns=['DayOfWeek', 'StoreType', 'Assortment', 'StateHoliday'], drop_first=True)\n",
        "\n",
        "# Преобразуем логические значения в целочисленные\n",
        "for column in data.select_dtypes(include=['bool']).columns:\n",
        "    data[column] = data[column].astype(int)"
      ],
      "metadata": {
        "id": "BlYfySejnmK5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Далее разбиваем данные и подготавливаем последовательности\n",
        "train_size = int(len(data) * 0.05)\n",
        "test_size = int(len(data) * 0.05)\n",
        "train_data = data.iloc[:train_size]\n",
        "test_data = data.iloc[train_size:]\n",
        "\n",
        "# Функция создания последовательностей\n",
        "def create_sequences(X, y, time_steps=14):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# разделяем данные на признаки и целевую переменную\n",
        "X_train = train_data.drop(columns=['Sales']).values\n",
        "y_train = train_data['Sales'].values\n",
        "X_test = test_data.drop(columns=['Sales']).values\n",
        "y_test = test_data['Sales'].values"
      ],
      "metadata": {
        "id": "rWRvpY81w_ph"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализуем данные через StandartScaler\n",
        "# Делаем так, чтобы все признаки имели одинаковый масштаб\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Создаём последовательности данных длинной в 2 недели\n",
        "time_steps = 14\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, time_steps)"
      ],
      "metadata": {
        "id": "3o8xeFv7yyuN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаём модельку\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(layers.LSTM(32, activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "UXudqjbt0BOX",
        "outputId": "7bfeaa40-8128-46ad-fa9a-cdd3dad7ec7f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m23,552\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">23,552</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,001\u001b[0m (140.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,001</span> (140.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,001\u001b[0m (140.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,001</span> (140.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "# Стоит переключиться на GPU\n",
        "history = model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=64, validation_split=0.1, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbjd6IoJ0Hp9",
        "outputId": "ae6b00ae-80b9-4c9b-fa26-9687820c0b6c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - loss: 20135584.0000 - val_loss: 7318919.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 7013385.0000 - val_loss: 6643561.5000\n",
            "Epoch 3/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 6863786.0000 - val_loss: 6341965.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 6406606.0000 - val_loss: 6006550.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - loss: 5829451.5000 - val_loss: 6675170.5000\n",
            "Epoch 6/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 5522030.0000 - val_loss: 5508163.5000\n",
            "Epoch 7/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - loss: 4998227.0000 - val_loss: 5552277.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - loss: 4107240.2500 - val_loss: 3966975.2500\n",
            "Epoch 9/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 3357031.2500 - val_loss: 3131206.7500\n",
            "Epoch 10/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 2668907.5000 - val_loss: 2941707.7500\n",
            "Epoch 11/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 2250551.7500 - val_loss: 2905812.2500\n",
            "Epoch 12/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 2030239.3750 - val_loss: 2235851.7500\n",
            "Epoch 13/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1836357.8750 - val_loss: 2117007.7500\n",
            "Epoch 14/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1563375.1250 - val_loss: 2006573.1250\n",
            "Epoch 15/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1587852.7500 - val_loss: 2415913.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 1369512.6250 - val_loss: 2137907.5000\n",
            "Epoch 17/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1334262.5000 - val_loss: 1830305.7500\n",
            "Epoch 18/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 1295494.1250 - val_loss: 1701299.6250\n",
            "Epoch 19/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 1229924.6250 - val_loss: 1579484.7500\n",
            "Epoch 20/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1104044.6250 - val_loss: 1769147.6250\n",
            "Epoch 21/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1011008.9375 - val_loss: 1420453.7500\n",
            "Epoch 22/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1122195.1250 - val_loss: 1506596.6250\n",
            "Epoch 23/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - loss: 937774.0625 - val_loss: 1499989.7500\n",
            "Epoch 24/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 1010476.1250 - val_loss: 2279601.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1178851.0000 - val_loss: 1450770.8750\n",
            "Epoch 26/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 888470.3125 - val_loss: 1325715.7500\n",
            "Epoch 27/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 878639.3750 - val_loss: 1323853.2500\n",
            "Epoch 28/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 955429.3125 - val_loss: 1326153.5000\n",
            "Epoch 29/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 855902.6250 - val_loss: 1321108.6250\n",
            "Epoch 30/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 849909.8750 - val_loss: 1342230.3750\n",
            "Epoch 31/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 804444.3125 - val_loss: 1429333.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 793081.8125 - val_loss: 1438032.6250\n",
            "Epoch 33/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 778216.8750 - val_loss: 1182909.2500\n",
            "Epoch 34/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 747281.0625 - val_loss: 1822872.6250\n",
            "Epoch 35/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 712916.4375 - val_loss: 1274714.8750\n",
            "Epoch 36/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 698562.3750 - val_loss: 1210228.7500\n",
            "Epoch 37/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 782115.0625 - val_loss: 1273967.5000\n",
            "Epoch 38/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - loss: 705742.5625 - val_loss: 1143484.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - loss: 642987.6875 - val_loss: 1467041.6250\n",
            "Epoch 40/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 623787.7500 - val_loss: 1300166.6250\n",
            "Epoch 41/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 662836.8125 - val_loss: 1223027.8750\n",
            "Epoch 42/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 626700.4375 - val_loss: 1185359.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 585294.1250 - val_loss: 1064528.7500\n",
            "Epoch 44/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 614522.0625 - val_loss: 1154724.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 574060.9375 - val_loss: 1272592.5000\n",
            "Epoch 46/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 557044.3125 - val_loss: 1314203.3750\n",
            "Epoch 47/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 563115.7500 - val_loss: 1222182.6250\n",
            "Epoch 48/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 563162.1875 - val_loss: 1136085.7500\n",
            "Epoch 49/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 525678.6875 - val_loss: 1191878.3750\n",
            "Epoch 50/50\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 556785.1250 - val_loss: 1603102.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Замечаем, что ошибка получилась не очень б_б\n",
        "# Прописываем функцию для предсказывания и визуализации результатов\n",
        "def plot_real_data_predictions(X_test_scaled, y_test, time_steps, model, test_size, total_data_len):\n",
        "    current_start = 0\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    while current_start < len(X_test_scaled):\n",
        "        end_idx = current_start + test_size\n",
        "        if end_idx >= len(X_test_scaled):\n",
        "            end_idx = len(X_test_scaled)\n",
        "\n",
        "        X_test_seq, y_test_seq = create_sequences(X_test_scaled[current_start:end_idx], y_test[current_start:end_idx], time_steps)\n",
        "        y_test_pred = model.predict(X_test_seq)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(y_test_seq, label='Настоящие значения')\n",
        "        plt.plot(y_test_pred, label='Предсказанные значения')\n",
        "        plt.legend()\n",
        "        plt.title(f'Предсказания с {current_start} по {end_idx}')\n",
        "        plt.show()\n",
        "\n",
        "        current_start += test_size"
      ],
      "metadata": {
        "id": "AM20vc4Y3sPH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вызываем нашу функцию и результаты\n",
        "total_data_len = len(data)\n",
        "plot_real_data_predictions(X_test_scaled, y_test, time_steps, model, test_size, total_data_len)\n",
        "# Можно абалдеть от того сколько времени будут строиться наши предсказания"
      ],
      "metadata": {
        "id": "wYCzcVdz4DF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Самостоятельная работа"
      ],
      "metadata": {
        "id": "_urH9w0O6R4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Изменить количество временных шагов (timestamps)\n",
        "\n",
        "```python\n",
        "# Пример изменения time_steps\n",
        "time_steps = 7\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, time_steps)\n",
        "```\n",
        "\n",
        "Или можно сразу прописать изменение в функции\n",
        "\n",
        "```python\n",
        "def create_sequences(data, time_steps=14):\n",
        "    sequences, labels = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        sequences.append(data[i:i+time_steps])\n",
        "        labels.append(data[i+time_steps])\n",
        "    return np.array(sequences), np.array(labels)\n",
        "```\n"
      ],
      "metadata": {
        "id": "5mBT_DHl7UgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если мы уменьшим количество дней, то можно заметить, что ошибка значительно уменьшится, что логично, так как предсказания будут строиться на меньшее кол-во дней. Если же наоборот увеличить количество дней, то ошибка значительно возрастёт и предсказания уже не будут такими точными\n",
        "\n",
        "p.s. Ну, по крайней мере у меня так)"
      ],
      "metadata": {
        "id": "mAhEA3b094dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Изменить количество слоёв в модели\n",
        "\n",
        "#### Ожидаемые эффекты\n",
        "Меньшее количество нейронов:\n",
        "\n",
        "+ Уменьшение количества нейронов может ускорить обучение и уменьшить объём ресурсов, требуемых для расчёта.\n",
        "+ Однако модель может потерять способность захватывать сложные зависимости, и точность прогноза может снизиться.\n",
        "\n",
        "Большее количество нейронов:\n",
        "\n",
        "+ Увеличение количества нейронов может улучшить способность модели выявлять более сложные паттерны, особенно в случае временных рядов с большим количеством данных.\n",
        "+ Но это также может привести к переобучению, если количество данных недостаточно, и модель начинает подстраиваться под шум.\n",
        "+ Большее количество нейронов увеличивает вычислительную сложность и время обучения, что нужно учитывать.\n",
        "\n",
        "#### Что у меня получилось заметить:\n",
        "\n",
        "Увеличив кол-во нейронов модель (возможно мне показалась) стала медленнее обучаться. Увеличился коэф-ент ошибки и в целом, модель начала переобучаться. Понял я это так как ошибка стала постоянно скакать от меньшего к большему, а потом и вовсе стала возрастать, что является первым признаком переобучения.\n",
        "\n",
        "Если попробовать уменьшить нейронов в модели, то ошибка снова возрастёт, а сама эффективность модели (предсказательные возмости) станут хуже.\n",
        "\n",
        "В целом, за счёт добавления новых слоёв и оптимизации обучения модели можно будет добиться идеального результата"
      ],
      "metadata": {
        "id": "1IOGpFDB_rdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Добавить слой Dropout для борьбы с переобучением\n",
        "\n",
        "#### Ожидаемые эффекты:\n",
        "+ Улучшение обобщающей способности: Dropout заставляет модель полагаться на все нейроны, что способствует более «устойчивому» обучению.\n",
        "+ Увеличение времени обучения: Поскольку каждый шаг будет обучаться с неполным набором активных нейронов, это может замедлить обучение, но часто улучшает точность на тестовых данных.\n",
        "\n",
        "#### Что у меня получилось заметить:\n",
        "\n",
        "Модель не стала дольше обучаться. Возможно сама архитектура задачи не сильно реагирует на изменение с помощью dropout. На каждую итерацию уходило по 2 - 3 секунды. Мне кажется, что модель наоборот стала обучаться быстрее, особенно это заметно если сравнивать пример из материалов урока и нашу модель.\n",
        "\n",
        "Мной не было замечено никаких минусов. Думаю что в данной задаче можно смело использовать dropout. Ошибка никак не изменилась, выходные результаты будто бы тоже.\n",
        "\n",
        "*Ещё хотел бы отметить, что в модели значительно увеличилось кол-во параметров*"
      ],
      "metadata": {
        "id": "NkoLe6o5CKKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Добавить больше слоев LSTM\n",
        "\n",
        "#### Ожидаемые эффекты\n",
        "- Большее количество слоев LSTM может повысить точность модели на сложных данных, если в данных присутствуют длительные зависимости.\n",
        "- Риск переобучения: Слишком много слоев может привести к переобучению, особенно если количество данных ограничено.\n",
        "- Возросшая вычислительная сложность: Добавление слоев увеличивает количество параметров, что потребует больше вычислительных ресурсов.\n",
        "\n",
        "#### Что у меня получилось заметить:\n",
        "\n",
        "Заметно, что сам процесс обучения у модели стал проходить труднее (если можно так выразиться), так как процент ошибки стал падать медленнее. Также увеличилось время, необходимое для полного обучения модели. Если в dropout на обучение одной эпохи уходило 2 секунды, сейчас уходит 5 (без dropout)\n",
        "\n",
        "Я пробовал использовать такую конфигурацию:\n",
        "\n",
        "```python\n",
        "# Модель с дополнительными слоями LSTM\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(layers.LSTM(64, activation='relu', return_sequences=True))  # Добавлен еще один LSTM слой\n",
        "model.add(layers.LSTM(32, activation='relu'))  # Новый заключительный LSTM слой\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "```"
      ],
      "metadata": {
        "id": "imIGcrAmH9ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Изменить функцию активации на других слоях\n",
        "\n",
        "#### Ожидаемые эффекты\n",
        "- Изменение динамики обучения: Активные функции влияют на скорость и стабильность обучения, и иногда tanh или sigmoid могут лучше выявлять зависимости, чем ReLU.\n",
        "- Лучшее качество предсказаний: В зависимости от типа данных функция активации может либо улучшить точность модели, либо замедлить её обучение, так что важно экспериментировать и сравнивать.\n",
        "\n",
        "В моём случае обе функции замедлили процесс обучения и значительно увеличили ошибку\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='tanh', return_sequences=True))  # Изменена активация на tanh\n",
        "model.add(layers.LSTM(64, activation='tanh'))  # Также изменена активация на tanh\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='sigmoid', return_sequences=True))  # Изменена активация на tanh\n",
        "model.add(layers.LSTM(64, activation='sigmoid'))  # Также изменена активация на tanh\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "```"
      ],
      "metadata": {
        "id": "A65-VX6zNwew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Использовать больше данных для обучения\n",
        "\n",
        "Я попробовал выделить 10 и 20 процентов данных для обучения модели. Заметил, что при увеличении данных значительно увеличивается время обучения. Для модели с dropout и выделенными 10 процентами для обучения, время обучения одной эпохи увеличелось с 2 секунд до 5 - 10 секунд. Процент ошибки незначительно возрос. Но, на выходные данные это особо не повлияло XD"
      ],
      "metadata": {
        "id": "48HG0gcZTmvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Изменить размер батча\n",
        "\n",
        "Ну и заключительное задание, связанное с изменением размера пакетов. Если увеличивать размер пакетов, то скорость обучения значительно возрастает, однако падает эффективность обучения модели (соответственно возрастает ошибка)\n",
        "\n",
        "Как раз на выходных данных видно наксколько сильно меняются результаты предсказания."
      ],
      "metadata": {
        "id": "qLBc-pZCUlfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестируем и балуемся"
      ],
      "metadata": {
        "id": "INf_Dpgy79gu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213d7ad2-e957-45e5-cea1-a4f5190d26fe",
        "id": "ghM02gM879gv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
            "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
            "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
            "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
            "       'Promo2SinceYear', 'PromoInterval'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Импортируем библиотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers # type: ignore (чтобы жёлтым не подчёркивало)\n",
        "\n",
        "# Сразу же подготавливаем наши файлы (store.csv | train.csv)\n",
        "train = pd.read_csv('train.csv', low_memory=False)\n",
        "store = pd.read_csv('store.csv')\n",
        "# Объединяем данные по идентификатору магазина\n",
        "data = pd.merge(train, store, on='Store', how='left')\n",
        "print(data.columns)\n",
        "# data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготавливаем признаки (извлекаем год, месяц, день | удаляем дату)\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "data = data.drop(columns=['Date'])\n",
        "\n",
        "# Удаляем ненужные строки и столбцы\n",
        "data = data[data['Open'] == 1]\n",
        "data = data.drop(columns=['Open', 'Customers'])\n",
        "\n",
        "# Заполняем пропуски значениями для корректного обучения\n",
        "data['CompetitionDistance'] = data['CompetitionDistance'].fillna(data['CompetitionDistance'].median())\n",
        "data['PromoInterval'], _ = pd.factorize(data['PromoInterval'])\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Преобразуем категориальные переменные в числовые\n",
        "data = pd.get_dummies(data, columns=['DayOfWeek', 'StoreType', 'Assortment', 'StateHoliday'], drop_first=True)\n",
        "\n",
        "# Преобразуем логические значения в целочисленные\n",
        "for column in data.select_dtypes(include=['bool']).columns:\n",
        "    data[column] = data[column].astype(int)"
      ],
      "metadata": {
        "id": "zFQFjTIO79gw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Далее разбиваем данные и подготавливаем последовательности\n",
        "train_size = int(len(data) * 0.05)\n",
        "test_size = int(len(data) * 0.05)\n",
        "train_data = data.iloc[:train_size]\n",
        "test_data = data.iloc[train_size:]\n",
        "\n",
        "# Функция создания последовательностей\n",
        "def create_sequences(X, y, time_steps=14):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# разделяем данные на признаки и целевую переменную\n",
        "X_train = train_data.drop(columns=['Sales']).values\n",
        "y_train = train_data['Sales'].values\n",
        "X_test = test_data.drop(columns=['Sales']).values\n",
        "y_test = test_data['Sales'].values"
      ],
      "metadata": {
        "id": "G9717u3C79gw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализуем данные через StandartScaler\n",
        "# Делаем так, чтобы все признаки имели одинаковый масштаб\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Создаём последовательности данных длинной в 2 недели\n",
        "time_steps = 7\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, time_steps)"
      ],
      "metadata": {
        "id": "mbrBvLmp79gx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание модели с добавлением Dropout\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))  # Dropout после первого LSTM слоя\n",
        "model.add(layers.LSTM(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))  # Dropout после второго LSTM слоя\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "76f90bc9-133d-49ba-9d6a-a41f3e37a124",
        "id": "fraOG70b79gx"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m79,872\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m129,345\u001b[0m (505.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,345</span> (505.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,345\u001b[0m (505.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,345</span> (505.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель с дополнительными слоями LSTM\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='relu', return_sequences=True))\n",
        "model.add(layers.LSTM(64, activation='relu', return_sequences=True))  # Добавлен еще один LSTM слой\n",
        "model.add(layers.LSTM(32, activation='relu'))  # Новый заключительный LSTM слой\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "YS6rpx5YGwTC",
        "outputId": "9bbc3e9c-6a1f-4279-adcb-2684ab51dd75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m79,872\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m141,729\u001b[0m (553.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,729</span> (553.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m141,729\u001b[0m (553.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,729</span> (553.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель с изменённой функцией активации\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='tanh', return_sequences=True))  # Изменена активация на tanh\n",
        "model.add(layers.LSTM(64, activation='tanh'))  # Также изменена активация на tanh\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "slDv8sWjOJZT",
        "outputId": "6b7bf766-2fcf-4b1e-ec07-6fa401922f82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m79,872\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m129,345\u001b[0m (505.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,345</span> (505.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,345\u001b[0m (505.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,345</span> (505.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(128, activation='sigmoid', return_sequences=True))\n",
        "model.add(layers.LSTM(64, activation='sigmoid'))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "rNVPU-weRTuj",
        "outputId": "21edd8b6-9116-4589-85df-e6058397049a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m79,872\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m129,345\u001b[0m (505.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,345</span> (505.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,345\u001b[0m (505.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,345</span> (505.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "# Стоит переключиться на GPU\n",
        "history = model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=512, validation_split=0.1, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f98113d-43d7-4734-9ca0-da57f3fe1a2c",
        "id": "SwKgpV1679gx"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 71ms/step - loss: 47777448.0000 - val_loss: 7814581.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8233192.0000 - val_loss: 7413561.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7490632.0000 - val_loss: 7115528.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7372843.0000 - val_loss: 6958172.5000\n",
            "Epoch 5/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7470914.5000 - val_loss: 6701439.5000\n",
            "Epoch 6/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7099585.0000 - val_loss: 6634939.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6771191.0000 - val_loss: 6565932.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6906929.0000 - val_loss: 6421429.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6701520.5000 - val_loss: 6291823.5000\n",
            "Epoch 10/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6513465.5000 - val_loss: 6115175.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6431991.0000 - val_loss: 5957417.5000\n",
            "Epoch 12/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6276433.0000 - val_loss: 5848560.5000\n",
            "Epoch 13/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5958102.0000 - val_loss: 5738706.5000\n",
            "Epoch 14/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5809436.0000 - val_loss: 5422600.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5630152.5000 - val_loss: 5196696.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5256925.5000 - val_loss: 4925175.5000\n",
            "Epoch 17/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5152586.5000 - val_loss: 4646127.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4828576.0000 - val_loss: 4604802.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4781541.5000 - val_loss: 4741566.5000\n",
            "Epoch 20/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4506437.5000 - val_loss: 4700797.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4126842.5000 - val_loss: 3828932.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3951020.0000 - val_loss: 3646049.5000\n",
            "Epoch 23/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3994026.2500 - val_loss: 3267673.2500\n",
            "Epoch 24/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3574797.5000 - val_loss: 3609577.7500\n",
            "Epoch 25/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3371644.7500 - val_loss: 3856077.5000\n",
            "Epoch 26/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3054123.0000 - val_loss: 3239865.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3031954.0000 - val_loss: 2573766.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3061451.5000 - val_loss: 2482428.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2644780.7500 - val_loss: 2863798.2500\n",
            "Epoch 30/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2589974.0000 - val_loss: 2417444.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2720106.2500 - val_loss: 2224686.2500\n",
            "Epoch 32/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2288924.2500 - val_loss: 2649549.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2229219.0000 - val_loss: 2041194.8750\n",
            "Epoch 34/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2206667.7500 - val_loss: 2610907.5000\n",
            "Epoch 35/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1987685.6250 - val_loss: 1935777.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2164870.5000 - val_loss: 2059277.8750\n",
            "Epoch 37/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1970671.5000 - val_loss: 2384201.5000\n",
            "Epoch 38/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1954560.3750 - val_loss: 1884929.3750\n",
            "Epoch 39/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1826819.3750 - val_loss: 3563038.5000\n",
            "Epoch 40/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1900565.2500 - val_loss: 1920951.1250\n",
            "Epoch 41/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1960170.7500 - val_loss: 1928851.8750\n",
            "Epoch 42/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1833946.5000 - val_loss: 1603082.5000\n",
            "Epoch 43/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1755080.3750 - val_loss: 1625187.5000\n",
            "Epoch 44/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1772635.7500 - val_loss: 1725851.3750\n",
            "Epoch 45/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1744914.3750 - val_loss: 1565765.3750\n",
            "Epoch 46/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1672751.5000 - val_loss: 1601715.5000\n",
            "Epoch 47/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1666025.5000 - val_loss: 1489709.5000\n",
            "Epoch 48/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1612673.1250 - val_loss: 1934191.3750\n",
            "Epoch 49/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1672442.2500 - val_loss: 1775153.8750\n",
            "Epoch 50/50\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1567714.5000 - val_loss: 1451237.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Замечаем, что ошибка получилась не очень б_б\n",
        "# Прописываем функцию для предсказывания и визуализации результатов\n",
        "def plot_real_data_predictions(X_test_scaled, y_test, time_steps, model, test_size, total_data_len):\n",
        "    current_start = 0\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    while current_start < len(X_test_scaled):\n",
        "        end_idx = current_start + test_size\n",
        "        if end_idx >= len(X_test_scaled):\n",
        "            end_idx = len(X_test_scaled)\n",
        "\n",
        "        X_test_seq, y_test_seq = create_sequences(X_test_scaled[current_start:end_idx], y_test[current_start:end_idx], time_steps)\n",
        "        y_test_pred = model.predict(X_test_seq)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(y_test_seq, label='Настоящие значения')\n",
        "        plt.plot(y_test_pred, label='Предсказанные значения')\n",
        "        plt.legend()\n",
        "        plt.title(f'Предсказания с {current_start} по {end_idx}')\n",
        "        plt.show()\n",
        "\n",
        "        current_start += test_size"
      ],
      "metadata": {
        "id": "gsGHUGmo79gx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вызываем нашу функцию и результаты\n",
        "total_data_len = len(data)\n",
        "plot_real_data_predictions(X_test_scaled, y_test, time_steps, model, test_size, total_data_len)\n",
        "# Можно абалдеть от того сколько времени будут строиться наши предсказания"
      ],
      "metadata": {
        "id": "p1cFDr-y79gy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}