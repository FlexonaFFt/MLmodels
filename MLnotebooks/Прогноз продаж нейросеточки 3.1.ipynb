{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Что такое LSTM?\n",
        "\n",
        "LSTM (Long Short-Term Memory) — это тип **рекуррентной нейронной сети (RNN)**, специально разработанный для работы с временными зависимостями. В отличие от стандартных RNN, LSTM лучше решает проблему **долговременной зависимости**, когда важные данные из начала временной последовательности могут теряться при передаче через множество шагов. Это делает LSTM особенно полезным для задач с последовательными данными, таких как временные ряды, текст и обработка последовательностей событий.\n",
        "\n",
        "### Как работают стандартные RNN?\n",
        "\n",
        "Чтобы понять, как работает LSTM, давайте коротко вспомним, как работают стандартные RNN:\n",
        "\n",
        "- **Рекуррентные нейронные сети (RNN)** обрабатывают данные последовательностей, используя информацию из предыдущих временных шагов для предсказания следующего значения. Это делается за счет того, что RNN имеют \"память\" — их скрытые состояния (нейроны) зависят не только от текущего входа, но и от всех предыдущих входов.\n",
        "  \n",
        "- **Проблема с RNN**: Хотя стандартные RNN могут обрабатывать временные зависимости, у них есть недостаток — они плохо работают с длинными последовательностями. По мере увеличения количества шагов RNN теряет важные сигналы из ранних временных шагов (например, данные, поступившие 100 шагов назад). Это называется **проблемой исчезающего градиента**.\n",
        "\n",
        "### Как LSTM решает проблему RNN?\n",
        "\n",
        "LSTM — это улучшенная версия RNN, которая была специально разработана, чтобы справляться с долгосрочными зависимостями. Основное отличие LSTM от стандартных RNN — это способ хранения информации на протяжении длительного времени.\n",
        "\n",
        "#### Основные компоненты LSTM:\n",
        "\n",
        "- **Ячейка памяти (cell state)**: Главная особенность LSTM — это наличие ячейки памяти, которая может сохранять информацию на протяжении долгого времени. Состояние ячейки обновляется с помощью специальных механизмов — **входных, выходных и забывчивых \"врат\" (gates)**.\n",
        "  \n",
        "- **Врата (forget gate)**: Определяют, какую информацию из ячейки памяти можно забыть на текущем шаге. Это важно для того, чтобы модель могла \"очищать\" память от ненужной информации, чтобы не перегружать её.\n",
        "\n",
        "- **Входные врата (input gate)**: Управляют тем, какую новую информацию можно добавить в ячейку памяти. Это позволяет LSTM обновлять память новыми данными, когда это нужно.\n",
        "\n",
        "- **Выходные врата (output gate)**: Решают, какую информацию из ячейки памяти использовать для текущего выхода и передачи на следующий шаг.\n",
        "\n",
        "Благодаря этим компонентам, LSTM может эффективно обучаться на данных с длинными зависимостями, где важная информация из начала последовательности может быть использована для предсказаний на более поздних шагах.\n",
        "\n",
        "---\n",
        "\n",
        "### Как LSTM применяется к задачам временных рядов?\n",
        "\n",
        "Когда мы работаем с **временными рядами** (например, с данными о продажах магазинов за несколько дней), важно учитывать зависимости между прошлыми событиями и текущим предсказанием. В нашем случае:\n",
        "\n",
        "- **Входные данные**: Это последовательности временных шагов, например, за последние 14 дней. Для каждого дня у нас есть набор признаков, таких как количество продаж, наличие акций, конкуренты и т.д.\n",
        "  \n",
        "- **LSTM-слой**: Каждый слой LSTM будет обрабатывать временные зависимости в данных. В отличие от стандартных полносвязных слоев, LSTM сохраняет информацию о последовательности событий и может использовать эту информацию для улучшения предсказания.\n",
        "  \n",
        "- **Выход**: На выходе LSTM предсказывает продажи на следующий день, основываясь на данных за предыдущие 14 дней. Модель может обновлять свои предсказания, обучаясь на каждой новой последовательности.\n",
        "\n",
        "---\n",
        "\n",
        "### Почему LSTM лучше, чем обычные нейронные сети для временных рядов?\n",
        "\n",
        "В задачах временных рядов важна не только текущая информация, но и история событий. Простая полносвязная нейронная сеть не может учесть взаимосвязи между предыдущими и текущими данными. В то же время LSTM:\n",
        "\n",
        "1. **Хранит информацию о последовательности**: Ячейка памяти и \"врата\" позволяют модели сохранять важные данные на протяжении всей последовательности.\n",
        "   \n",
        "2. **Предсказывает будущее на основе прошлого**: LSTM эффективно использует историю данных для предсказания будущих значений, что особенно полезно в задачах прогнозирования продаж, спроса, цен и других временных рядов."
      ],
      "metadata": {
        "id": "2LtLmZ222H_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Материал по созданию и обучению модели LSTM для прогнозирования продаж с использованием временных рядов\n",
        "\n",
        "В этом уроке мы пошагово разберем, как создать модель LSTM для прогнозирования продаж на основе временных рядов. Модель будет обучаться на первых 5% данных и тестироваться на разных сегментах данных с шагом в 5%.\n",
        "\n",
        "## Разбор кода\n",
        "\n",
        "### Шаг 0: Добавление датасета в блокнот\n",
        "\n",
        "Загрузите файлы `store.csv` и `train.csv` в файлы блокнота.\n",
        "\n",
        "Скачать датасет можно тут: https://drive.google.com/drive/folders/1B41RvyVuFayZRFcHuJwGO_ltdrQZCRWP?usp=sharing\n",
        "\n",
        "Источник датасета и информация о нём: https://www.kaggle.com/c/rossmann-store-sales/data\n",
        "\n",
        "### Шаг 1: Импорт необходимых библиотек\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- **pandas**: Библиотека для работы с табличными данными (DataFrame).\n",
        "- **numpy**: Используется для работы с массивами данных и числовыми вычислениями.\n",
        "- **tensorflow**: Библиотека для построения и обучения нейронных сетей. В частности, мы используем её для создания LSTM модели.\n",
        "- **sklearn.preprocessing.StandardScaler**: Стандартный скейлер, который используется для нормализации данных.\n",
        "- **matplotlib.pyplot**: Библиотека для визуализации графиков.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 2: Загрузка данных и их предобработка\n",
        "\n",
        "```python\n",
        "# Загрузка данных\n",
        "train = pd.read_csv('train.csv', low_memory=False)\n",
        "store = pd.read_csv('store.csv')\n",
        "\n",
        "# Объединение данных по идентификатору магазина (Store)\n",
        "data = pd.merge(train, store, on='Store', how='left')\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- **train.csv** содержит данные о продажах магазинов за определенные дни.\n",
        "- **store.csv** содержит дополнительную информацию о магазинах (например, расстояние до конкурентов).\n",
        "- Мы объединяем данные по столбцу `Store`, чтобы получить всю необходимую информацию в одном наборе данных.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 3: Предобработка данных\n",
        "\n",
        "```python\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "data = data.drop(columns=['Date'])\n",
        "\n",
        "data = data[data['Open'] == 1]\n",
        "data = data.drop(columns=['Open', 'Customers'])\n",
        "\n",
        "data['CompetitionDistance'] = data['CompetitionDistance'].fillna(data['CompetitionDistance'].median())\n",
        "data['PromoInterval'], _ = pd.factorize(data['PromoInterval'])\n",
        "data = data.fillna(0)\n",
        "\n",
        "data = pd.get_dummies(data, columns=['DayOfWeek', 'StoreType', 'Assortment', 'StateHoliday'], drop_first=True)\n",
        "\n",
        "for column in data.select_dtypes(include=['bool']).columns:\n",
        "    data[column] = data[column].astype(int)\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- **Преобразование даты**: Мы извлекаем признаки даты (год, месяц, день) и удаляем сам столбец даты.\n",
        "- **Удаление ненужных строк и столбцов**: Убираем строки, где магазин был закрыт (`Open == 0`), и удаляем ненужные столбцы, такие как `Customers` и `Open`.\n",
        "- **Обработка пропущенных значений**: Заполняем пропуски в данных о расстоянии до конкурентов (`CompetitionDistance`) медианным значением и преобразуем строковые значения в числовые в столбце `PromoInterval`.\n",
        "- **One-hot encoding**: Преобразуем категориальные переменные в числовые с помощью метода `get_dummies()`.\n",
        "- **Преобразование булевых значений**: Преобразуем логические значения в целочисленные (0 или 1).\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 4: Разбиение данных и подготовка последовательностей\n",
        "\n",
        "```python\n",
        "train_size = int(len(data) * 0.05)  # 5% данных для обучения\n",
        "test_size = int(len(data) * 0.05)  # Тестирование будет происходить на каждых 5% данных\n",
        "\n",
        "train_data = data.iloc[:train_size]\n",
        "test_data = data.iloc[train_size:]  # Остальные 95% для тестирования (каждые 5% будем тестировать по очереди)\n",
        "\n",
        "def create_sequences(X, y, time_steps=14):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train = train_data.drop(columns=['Sales']).values\n",
        "y_train = train_data['Sales'].values\n",
        "\n",
        "X_test = test_data.drop(columns=['Sales']).values\n",
        "y_test = test_data['Sales'].values\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- **Отбор данных**: Мы берем первые 5% данных для обучения модели, а остальные 95% данных будем использовать для тестирования.\n",
        "- **Функция создания последовательностей**: Для LSTM нам нужны последовательности данных, поэтому мы создаем временные окна длиной 14 дней (2 недели).\n",
        "- **Разделение на признаки и целевую переменную**: Мы отделяем столбец с продажами (`Sales`) от остальных признаков для обучения модели.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 5: Нормализация данных и создание последовательностей\n",
        "\n",
        "```python\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "time_steps = 14\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, time_steps)\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- Мы нормализуем данные с помощью **StandardScaler** для того, чтобы все признаки имели одинаковый масштаб. Это важно для ускорения сходимости модели и повышения её точности.\n",
        "- Затем мы создаем последовательности данных длиной 14 дней для подачи в LSTM.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 6: Создание LSTM модели\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "model.add(layers.LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(layers.LSTM(32, activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- **Последовательная модель**: Мы используем **Sequential** модель, в которую поочередно добавляем слои.\n",
        "- **Первый слой LSTM**: Обрабатывает последовательность длиной 14 дней (две недели). Каждый временной шаг содержит набор признаков.\n",
        "- **Второй слой LSTM**: Уменьшает количество нейронов до 32 и возвращает только последнее значение последовательности (предсказание на следующий день).\n",
        "- **Полносвязный слой (Dense)**: Этот слой отвечает за финальный вывод одного значения — предсказания продаж. Мы предсказываем продажи только на 1 день, на основе признаков за 14 предыдущих дней.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 7: Обучение модели\n",
        "\n",
        "```python\n",
        "history = model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=64, validation_split=0.1, verbose=1)\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- Модель обучается на 50 эпохах с использованием данных, разделенных на обучающую и валидационную выборки. Мы используем 10% данных для валидации.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 8: Функция для тестирования предсказаний с поддержкой реальных признаков\n",
        "\n",
        "```python\n",
        "def plot_real_data_predictions(X_test_scaled, y_test, time_steps, model, test_size, total_data_len):\n",
        "    current_start = 0\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    while current_start < len(X_test_scaled):\n",
        "        end_idx = current_start + test_size\n",
        "        if end_idx >= len(X_test_scaled):\n",
        "            end_idx = len(X_test_scaled)\n",
        "\n",
        "        X_test_seq, y_test_seq = create_sequences(X_test_scaled[current_start:end_idx], y_test[current_start:end_idx], time_steps)\n",
        "        y_test_pred = model.predict(X_test_seq)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(y_test_seq, label='Настоящие значения')\n",
        "        plt.plot(y_test_pred, label='Предсказанные значения')\n",
        "        plt.legend()\n",
        "        plt.title(f'Предсказания с {current_start} по {end_idx}')\n",
        "        plt.show()\n",
        "\n",
        "        current_start += test_size\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- Эта функция позволяет предсказывать и визуализировать результаты модели на тестовых данных с шагом в 5% данных.\n",
        "- Мы строим графики, сравнивая реальные значения продаж с предсказанными значениями, чтобы видеть, насколько хорошо модель справляется.\n",
        "\n",
        "---\n",
        "\n",
        "### Шаг 9: Вызов функции для тестирования и визуализации\n",
        "\n",
        "```python\n",
        "total_data_len = len(data)\n",
        "plot_real_data_predictions(X_test_scaled, y_test, time_steps, model, test_size, total_data_len)\n",
        "```\n",
        "\n",
        "**Описание:**\n",
        "- Мы запускаем функцию, которая предсказывает результаты с интервалом в 5% от общего объема данных и выводит их на график для оценки качества модели."
      ],
      "metadata": {
        "id": "Nr8nlzWfIPlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задачи для самостоятельного выполнения\n",
        "\n",
        "### 1. **Изменить количество временных шагов (timestamps)**\n",
        "   \n",
        "**Описание задачи**: В данный момент модель обучается на последовательностях длиной 14 дней (2 недели). Попробуйте изменить количество временных шагов на другие значения (например, 7, 30 или 60 дней) и проанализируйте, как это влияет на точность прогнозов.\n",
        "\n",
        "**Цель**:\n",
        "- Изучить, как длина последовательности (количество шагов назад) влияет на предсказания.\n",
        "- Найти оптимальное количество временных шагов для задачи прогнозирования продаж.\n",
        "\n",
        "**Задание**:\n",
        "- Измените параметр `time_steps` в функции `create_sequences()`.\n",
        "- Обучите модель и сравните результаты по MAE и графикам.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Изменить количество нейронов в слоях LSTM**\n",
        "\n",
        "**Описание задачи**: Мы использовали два слоя LSTM с 64 и 32 нейронами соответственно. Попробуйте изменить количество нейронов в каждом слое (например, увеличьте или уменьшите в два раза) и проанализируйте влияние этого на качество модели.\n",
        "\n",
        "**Цель**:\n",
        "- Найти оптимальное количество нейронов для слоев LSTM.\n",
        "- Понять, как сложность модели влияет на ее обучаемость и качество предсказаний.\n",
        "\n",
        "**Задание**:\n",
        "- Измените количество нейронов в слоях LSTM.\n",
        "- Обучите модель и проанализируйте, как это повлияло на скорость обучения и качество предсказаний.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Добавить слой Dropout для борьбы с переобучением**\n",
        "\n",
        "**Описание задачи**: Модель может переобучаться на обучающих данных, особенно если она сложная. Один из способов борьбы с переобучением — это добавление слоя **Dropout**, который случайным образом отключает некоторые нейроны во время обучения, предотвращая модель от заучивания специфичных шаблонов.\n",
        "\n",
        "**Цель**:\n",
        "- Улучшить обобщающую способность модели и снизить вероятность переобучения.\n",
        "\n",
        "**Задание**:\n",
        "- Добавьте слой `Dropout` после каждого слоя LSTM с вероятностью 0.2 или 0.3.\n",
        "- Обучите модель и проверьте, как это влияет на результаты на тестовых данных.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Добавить больше слоев LSTM**\n",
        "\n",
        "**Описание задачи**: Попробуйте добавить больше слоев LSTM. Например, вместо двух слоев добавьте три или четыре, чтобы модель могла лучше обрабатывать сложные зависимости во временных рядах.\n",
        "\n",
        "**Цель**:\n",
        "- Понять, как добавление дополнительных слоев LSTM может улучшить (или ухудшить) предсказания.\n",
        "- Проанализировать, как это влияет на вычислительную сложность и время обучения.\n",
        "\n",
        "**Задание**:\n",
        "- Добавьте еще один или два слоя LSTM.\n",
        "- Проверьте, как это изменение повлияло на результаты.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Изменить функцию активации на других слоях**\n",
        "\n",
        "**Описание задачи**: Мы используем функцию активации `ReLU` (Rectified Linear Unit) в слоях LSTM. Попробуйте заменить её на другие функции активации, такие как `tanh` или `sigmoid`, и посмотрите, как это влияет на обучение модели.\n",
        "\n",
        "**Цель**:\n",
        "- Понять, как функция активации влияет на результаты и обучаемость модели.\n",
        "\n",
        "**Задание**:\n",
        "- Измените функцию активации в слоях LSTM.\n",
        "- Обучите модель и сравните результаты с предыдущими экспериментами.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Использовать больше данных для обучения**\n",
        "\n",
        "**Описание задачи**: В данный момент мы используем только 5% данных для обучения. Попробуйте увеличить этот процент до 10% или 20% и посмотрите, как это влияет на качество предсказаний.\n",
        "\n",
        "**Цель**:\n",
        "- Изучить, как увеличение объема данных для обучения влияет на точность и обобщающую способность модели.\n",
        "\n",
        "**Задание**:\n",
        "- Увеличьте количество данных, например, до 10% или 20%, и обучите модель на большем объеме данных.\n",
        "- Проверьте, как это влияет на метрики модели.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Изменить размер батча**\n",
        "\n",
        "**Описание задачи**: В текущем коде размер батча установлен на 64. Попробуйте изменить этот параметр на более маленькие (например, 32) или большие значения (например, 128), чтобы изучить, как это влияет на время обучения и точность модели.\n",
        "\n",
        "**Цель**:\n",
        "- Найти оптимальный размер батча для ускорения обучения и улучшения качества предсказаний.\n",
        "\n",
        "**Задание**:\n",
        "- Измените параметр `batch_size` на 32 или 128 и посмотрите, как это повлияет на результаты.\n",
        "- Сравните результаты при разных размерах батча.\n",
        "\n",
        "---\n",
        "\n",
        "Эти задачи помогут вам лучше понять, как архитектура модели и гиперпараметры влияют на её обучение и точность. Экспериментируя с архитектурой LSTM, количеством временных шагов и другими параметрами, вы сможете улучшить производительность модели и лучше понять, как LSTM работает с временными рядами."
      ],
      "metadata": {
        "id": "24Y9WpIW1bA1"
      }
    }
  ]
}